// [[RARO]]/apps/web-console/src/lib/mock-api.ts
import { type WorkflowConfig, type ArtifactMetadata } from './api';

// --- Types ---
type TopologySnapshot = {
    nodes: string[];
    edges: Array<{ from: string; to: string }>;
};

type SimulationStep = {
    delay: number;
    state: {
        status: string;
        active_agents: string[];
        completed_agents: string[];
        failed_agents: string[];
        total_tokens_used: number;
        invocations: Array<{
            id: string;
            agent_id: string;
            status: 'success' | 'failed';
            tokens_used: number;
            latency_ms: number;
            artifact_id?: string;
            error_message?: string;
        }>;
    };
    signatures?: Record<string, string>;
    topology?: TopologySnapshot;
    // New: Action to execute when this step triggers (for emitting logs)
    action?: () => void;
};

// --- Mock Data Generators ---

const generateDelegationArtifact = (reason: string, parentId: string, newAgentId: string) => {
    const payload = {
        reason: reason,
        strategy: "child",
        new_nodes: [
            {
                id: newAgentId,
                role: "worker",
                model: "gemini-2.5-flash",
                prompt: `Dynamically delegated task from ${parentId}`,
                tools: ["web_search"],
                depends_on: [parentId]
            }
        ]
    };

    return `I need to delegate a sub-task to handle this request properly.

\`\`\`json:delegation
${JSON.stringify(payload, null, 2)}
\`\`\`

Delegating execution to ${newAgentId}...`;
};

const STATIC_ARTIFACTS: Record<string, any> = {
    'n1': {
        result: `## Orchestration Plan
Analysis indicates a need for deep retrieval and verification.
1. **Retrieval**: Gather architecture docs.
2. **Analysis**: Profile latency metrics.
3. **Synthesis**: Generate final report.`
    },
    'n3': {
        success: true,
        result: `Analysis complete. Generated visualization of latency metrics across all service endpoints.

Key Findings:
- P99 latency variance: 0.042ms
- 3 outlier endpoints identified
- Peak load correlation: 0.87

The variance analysis chart and raw data have been saved to disk.

[SYSTEM: Generated Image saved to 'latency_variance_analysis.png']
[SYSTEM: Generated File saved to 'fictional_data.json']`,
        // UPDATED: Include both image and JSON to test ArtifactCard logic
        files_generated: ['latency_variance_analysis.png', 'fictional_data.json'],
        artifact_stored: true
    },
    'n4': {
        result: `# Final Report
The analysis confirms that the latency regression is caused by "Cold Expert" switching in the MoE layer.
**Recommendation**: Enable pre-warming on the Orchestrator.`
    }
};

// --- Singleton for Controlling the Active Simulation ---
let activeSocket: MockWebSocket | null = null;

// --- API Methods ---

export async function mockStartRun(config: WorkflowConfig): Promise<{ success: boolean; run_id: string }> {
    console.log('[MOCK] Starting run with config:', config);
    return new Promise((resolve) => {
        setTimeout(() => {
            resolve({
                success: true,
                run_id: `mock-run-${Date.now()}`
            });
        }, 500);
    });
}

// Global artifact store to hold dynamic outputs during a session
let SESSION_ARTIFACTS: Record<string, any> = {};

export async function mockGetArtifact(runId: string, agentId: string): Promise<any> {
    console.log(`[MOCK] Fetching artifact for ${agentId}`);
    return new Promise((resolve) => {
        setTimeout(() => {
            const artifact = SESSION_ARTIFACTS[agentId] || STATIC_ARTIFACTS[agentId];
            resolve(artifact || { text: `[MOCK] Output generated by agent ${agentId}.` });
        }, 600); 
    });
}

// ** NEW: Mock Pause/Resume Handlers **
export async function mockResumeRun(runId: string): Promise<void> {
    console.log(`[MOCK] Resuming run ${runId}`);
    if (activeSocket) {
        activeSocket.resume();
    }
}

export async function mockStopRun(runId: string): Promise<void> {
    console.log(`[MOCK] Stopping run ${runId}`);
    if (activeSocket) {
        activeSocket.close();
    }
}

// === NEW MOCK RFS ===
export async function mockGetLibraryFiles(): Promise<string[]> {
    return [
        'financials_Q3_2024.pdf',
        'system_architecture_v2.md',
        'raw_telemetry_dump.csv',
        'cortex_safety_policy.json'
    ];
}

// === MOCK GENERATED FILE SERVER ===
// Simple bar chart SVG for mock demonstration
const MOCK_CHART_SVG = `
<svg width="600" height="400" xmlns="http://www.w3.org/2000/svg">
  <style>
    .title { font: bold 16px monospace; fill: #333; }
    .label { font: 11px monospace; fill: #666; }
    .bar { fill: #4285f4; }
    .grid { stroke: #e0e0e0; stroke-width: 1; }
  </style>

  <!-- Background -->
  <rect width="600" height="400" fill="#fafafa"/>

  <!-- Title -->
  <text x="300" y="30" text-anchor="middle" class="title">P99 Latency Variance Analysis</text>

  <!-- Grid Lines -->
  <line x1="80" y1="100" x2="80" y2="350" class="grid"/>
  <line x1="80" y1="350" x2="550" y2="350" class="grid"/>

  <!-- Bars -->
  <rect x="120" y="180" width="60" height="170" class="bar"/>
  <rect x="220" y="120" width="60" height="230" class="bar"/>
  <rect x="320" y="200" width="60" height="150" class="bar"/>
  <rect x="420" y="90" width="60" height="260" class="bar"/>

  <!-- Labels -->
  <text x="150" y="370" text-anchor="middle" class="label">Auth</text>
  <text x="250" y="370" text-anchor="middle" class="label">Search</text>
  <text x="350" y="370" text-anchor="middle" class="label">Data</text>
  <text x="450" y="370" text-anchor="middle" class="label">Upload</text>

  <!-- Y-axis labels -->
  <text x="70" y="355" text-anchor="end" class="label">0ms</text>
  <text x="70" y="225" text-anchor="end" class="label">50ms</text>
  <text x="70" y="105" text-anchor="end" class="label">100ms</text>

  <!-- Variance annotation -->
  <text x="300" y="385" text-anchor="middle" class="label">Variance: 0.042ms</text>
</svg>`;

const MOCK_RESEARCH_CHART_SVG = `
<svg width="700" height="500" xmlns="http://www.w3.org/2000/svg">
  <style>
    .title { font: bold 18px monospace; fill: #2c3e50; }
    .subtitle { font: 12px monospace; fill: #7f8c8d; }
    .line { stroke: #e74c3c; stroke-width: 3; fill: none; }
    .point { fill: #e74c3c; }
    .grid { stroke: #ecf0f1; stroke-width: 1; }
    .axis-label { font: 11px monospace; fill: #95a5a6; }
  </style>

  <rect width="700" height="500" fill="#ffffff"/>

  <text x="350" y="30" text-anchor="middle" class="title">Research Findings Timeline</text>
  <text x="350" y="50" text-anchor="middle" class="subtitle">Key Insights Distribution (Q1-Q4 2024)</text>

  <!-- Grid -->
  <line x1="80" y1="100" x2="80" y2="420" class="grid" stroke-width="2"/>
  <line x1="80" y1="420" x2="650" y2="420" class="grid" stroke-width="2"/>

  <!-- Data Line -->
  <polyline points="100,380 200,320 300,280 400,200 500,240 600,160" class="line"/>

  <!-- Data Points -->
  <circle cx="100" cy="380" r="6" class="point"/>
  <circle cx="200" cy="320" r="6" class="point"/>
  <circle cx="300" cy="280" r="6" class="point"/>
  <circle cx="400" cy="200" r="6" class="point"/>
  <circle cx="500" cy="240" r="6" class="point"/>
  <circle cx="600" cy="160" r="6" class="point"/>

  <!-- X-axis labels -->
  <text x="100" y="445" text-anchor="middle" class="axis-label">Jan</text>
  <text x="200" y="445" text-anchor="middle" class="axis-label">Mar</text>
  <text x="300" y="445" text-anchor="middle" class="axis-label">May</text>
  <text x="400" y="445" text-anchor="middle" class="axis-label">Jul</text>
  <text x="500" y="445" text-anchor="middle" class="axis-label">Sep</text>
  <text x="600" y="445" text-anchor="middle" class="axis-label">Nov</text>

  <!-- Y-axis labels -->
  <text x="70" y="425" text-anchor="end" class="axis-label">0</text>
  <text x="70" y="325" text-anchor="end" class="axis-label">25</text>
  <text x="70" y="225" text-anchor="end" class="axis-label">50</text>
  <text x="70" y="125" text-anchor="end" class="axis-label">75</text>
</svg>`;

const MOCK_EXECUTIVE_SUMMARY_MD = `# Executive Summary

**Report Generated**: ${new Date().toLocaleDateString()}
**Workflow**: Research & Analysis Pipeline
**Status**: âœ“ Complete

---

## Key Findings

### 1. Market Analysis
The comprehensive market research indicates a **42% growth opportunity** in the target segment over the next fiscal year. Primary drivers include:

- Increased demand for automation solutions (+35%)
- Emerging markets expansion (+18%)
- Technology adoption acceleration (+28%)

### 2. Competitive Landscape

| Competitor | Market Share | Growth Rate | Key Advantage |
|------------|--------------|-------------|---------------|
| Alpha Corp | 32%          | +12%        | Brand Recognition |
| Beta Inc   | 28%          | +8%         | Price Leadership |
| Gamma Ltd  | 15%          | +22%        | Innovation |
| **Our Position** | **25%** | **+18%** | **Service Quality** |

### 3. Strategic Recommendations

#### Immediate Actions (Q1 2025)
1. **Product Diversification**: Expand portfolio with 3 new SKUs
2. **Market Penetration**: Target 5 new geographic regions
3. **Technology Investment**: Allocate $2.5M for R&D initiatives

#### Medium-Term Goals (2025-2026)
- Achieve 30% market share
- Reduce operational costs by 15%
- Increase customer retention to 92%

### 4. Risk Assessment

**High Priority Risks**:
- Supply chain volatility (Probability: 65%, Impact: High)
- Regulatory changes (Probability: 40%, Impact: Medium)
- Competitive price wars (Probability: 55%, Impact: High)

**Mitigation Strategies**:
- Diversify supplier base (3+ vendors per critical component)
- Establish regulatory compliance task force
- Focus on value-add services vs. price competition

---

## Financial Projections

\`\`\`
Year    Revenue    Growth    EBITDA    Margin
2024    $45.2M     +18%      $12.4M    27.4%
2025    $58.7M     +30%      $17.8M    30.3%
2026    $78.3M     +33%      $25.1M    32.1%
\`\`\`

---

## Conclusion

The research findings support a **STRONG BUY** recommendation for strategic expansion initiatives. Market conditions are favorable, competitive positioning is solid, and execution capabilities are proven.

**Next Steps**:
1. Board approval for Q1 initiatives
2. Resource allocation finalization
3. KPI tracking dashboard deployment

---

*This report was generated by the RARO autonomous research pipeline.*
*For questions, contact the Strategy Team.*
`;

const MOCK_ANOMALY_LOG_CSV = `timestamp,severity,component,message,correlation_id
2024-01-09T08:15:23Z,WARNING,auth-service,Failed login attempt from IP 192.168.1.45,corr-001
2024-01-09T08:16:42Z,ERROR,database,Connection timeout to replica-2,corr-002
2024-01-09T08:17:15Z,WARNING,api-gateway,Rate limit exceeded for client_abc123,corr-003
2024-01-09T08:18:33Z,CRITICAL,payment-processor,Transaction validation failed - insufficient funds,corr-004
2024-01-09T08:19:01Z,WARNING,auth-service,Failed login attempt from IP 192.168.1.45,corr-005
2024-01-09T08:20:12Z,ERROR,cache-layer,Redis connection lost - failover initiated,corr-006
2024-01-09T08:21:45Z,WARNING,api-gateway,Rate limit exceeded for client_abc123,corr-007
2024-01-09T08:22:33Z,ERROR,message-queue,RabbitMQ consumer lag exceeds threshold,corr-008
2024-01-09T08:23:18Z,CRITICAL,auth-service,Brute force attack detected from IP 192.168.1.45,corr-009
2024-01-09T08:24:55Z,WARNING,database,Slow query detected (5.2s) on users table,corr-010
2024-01-09T08:25:22Z,ERROR,storage-service,S3 bucket access denied - check IAM roles,corr-011
2024-01-09T08:26:40Z,WARNING,notification-service,Email delivery delayed - SMTP timeout,corr-012
2024-01-09T08:27:13Z,CRITICAL,payment-processor,Payment gateway unreachable - network issue,corr-013
2024-01-09T08:28:02Z,ERROR,api-gateway,Invalid JWT signature from client_xyz789,corr-014
2024-01-09T08:29:31Z,WARNING,monitoring,Disk usage at 87% on server-prod-3,corr-015`;

const MOCK_GENERATED_FILES: Record<string, string> = {
    'latency_variance_analysis.png': 'data:image/svg+xml;charset=utf-8,' + encodeURIComponent(MOCK_CHART_SVG),
    'metrics_summary.json': 'data:application/json;charset=utf-8,' + encodeURIComponent(JSON.stringify({
        p99_variance: 0.042,
        outliers: ['endpoint_auth', 'endpoint_search', 'endpoint_upload'],
        peak_correlation: 0.87,
        generated_at: new Date().toISOString()
    }, null, 2)),
    'executive_summary.md': 'data:text/markdown;charset=utf-8,' + encodeURIComponent(MOCK_EXECUTIVE_SUMMARY_MD),
    'research_chart.png': 'data:image/svg+xml;charset=utf-8,' + encodeURIComponent(MOCK_RESEARCH_CHART_SVG),
    'security_report.pdf': 'data:text/plain;charset=utf-8,' + encodeURIComponent('PDF Preview: Security Audit Report\n\n[This is a mock PDF file - actual PDF rendering not available in demo mode]\n\nReport Summary:\n- 15 vulnerabilities identified\n- 8 critical issues resolved\n- System compliance: 94%\n- Next audit: Q2 2025'),
    'anomaly_log.csv': 'data:text/csv;charset=utf-8,' + encodeURIComponent(MOCK_ANOMALY_LOG_CSV),
    // UPDATED: Added the JSON file from your logs
    'fictional_data.json': 'data:application/json;charset=utf-8,' + encodeURIComponent(JSON.stringify([
        { "id": 1, "name": "John Doe", "email": "john@example.com", "age": 28 },
        { "id": 2, "name": "Jane Smith", "email": "jane@test.org", "age": 34 }
    ], null, 2)),
};

export function getMockGeneratedFile(filename: string): string | null {
    return MOCK_GENERATED_FILES[filename] || null;
}


// --- Mock WebSocket Class ---

export class MockWebSocket {
    url: string;
    onopen: (() => void) | null = null;
    onmessage: ((event: { data: string }) => void) | null = null;
    onclose: ((e: { code: number; reason: string; wasClean: boolean }) => void) | null = null;
    onerror: ((err: any) => void) | null = null;
    
    private steps: SimulationStep[] = [];
    private currentStep = 0;
    private timer: any;
    private isPaused = false;

    // Current State Trackers
    private topology: TopologySnapshot;
    private activeAgents: string[] = [];
    private completedAgents: string[] = [];
    private invocations: any[] = [];
    private signatures: Record<string, string> = {};
    private totalTokens = 0;

    constructor(url: string) {
        this.url = url;
        activeSocket = this; // Register singleton
        
        SESSION_ARTIFACTS = {};
        
        this.topology = {
            nodes: ['n1', 'n2', 'n3', 'n4'],
            edges: [
                { from: 'n1', to: 'n2' },
                { from: 'n1', to: 'n3' },
                { from: 'n2', to: 'n4' },
                { from: 'n3', to: 'n4' }
            ]
        };

        this.planSimulation();
        
        setTimeout(() => {
            if (this.onopen) this.onopen();
            this.runLoop();
        }, 500);
    }

    // Called by the external mockResumeRun API
    resume() {
        if (this.isPaused) {
            console.log('[MOCK WS] Resuming simulation...');
            this.isPaused = false;
            // Emit a resumed log
            this.emitLog('KERNEL', 'INFO', 'Resuming execution loop', 'SYS');
            this.runLoop();
        }
    }

    send(data: any) {
        console.log('[MOCK WS] Received:', data);
    }

    close() {
        console.log('[MOCK WS] Closing connection');
        clearTimeout(this.timer);
        activeSocket = null;
        
        if (this.onclose) {
            this.onclose({ 
                code: 1000, 
                reason: 'Mock Simulation Ended', 
                wasClean: true 
            });
        }
    }

    /**
     * Helper to emit live log events (for ToolExecutionCard testing)
     */
    private emitLog(agentId: string, category: string, message: string, metadata: string) {
        const payload = {
            type: 'log_event',
            agent_id: agentId,
            payload: {
                category: category,
                message: message,
                metadata: metadata
            },
            timestamp: new Date().toISOString()
        };

        if (this.onmessage) {
            this.onmessage({ data: JSON.stringify(payload) });
        }
    }

    private planSimulation() {
        // 1. Start State
        this.addStep(500, 'RUNNING');

        // 2. Orchestrator (n1) - Thinking logic
        this.addStep(200, undefined, () => {
             this.activeAgents.push('n1');
             this.emitLog('n1', 'THOUGHT', 'Analyzing workflow requirements...', 'PLANNING');
        });
        this.simulateAgentExecution('n1', 1500, 450);

        // 3. Start Parallel Execution
        this.addStep(200, undefined, () => {
             this.activeAgents.push('n2', 'n3');
        });

        // --- AGENT n3: PYTHON TOOL USER ---
        // Simulating the Tool Loop from llm.py
        this.addStep(800, undefined, () => {
            this.emitLog('n3', 'THOUGHT', 'I need to calculate variance using pandas.', 'REASONING');
        });

        // 3a. Call Tool
        this.addStep(400, undefined, () => {
            // "IO_REQ" + "TOOL_CALL" triggers blue spinner in ToolExecutionCard
            this.emitLog('n3', 'TOOL_CALL', 'execute_python({"code": "import pandas as pd\\ndf = pd.read_csv(\'data.csv\')..."})', 'IO_REQ');
        });

        // 3b. Tool Result (Success)
        this.addStep(1500, undefined, () => {
             // "IO_OK" + "TOOL_RESULT" triggers green check in ToolExecutionCard
             // UPDATED: Include both files in the log message to trigger the UI ArtifactCards
             this.emitLog('n3', 'TOOL_RESULT', 'Files generated: [\'latency_variance_analysis.png\', \'fictional_data.json\']\nStandard Output: Done.', 'IO_OK');
        });
        
        // Complete n3
        this.simulateAgentCompletion('n3', 500, 800, false);

        // --- AGENT n2: DELEGATOR + ERROR SIMULATION ---
        this.addStep(500, undefined, () => {
             // Simulate a failed tool call first to test the Error Card
             this.emitLog('n2', 'TOOL_CALL', 'web_search({"query": "internal_docs_v2"})', 'IO_REQ');
        });

        this.addStep(1200, undefined, () => {
            // "IO_ERR" + "TOOL_RESULT" triggers red Error Card with traceback support
            this.emitLog('n2', 'TOOL_RESULT', 'Error: Connection Timeout\nTraceback (most recent call last):\n  File "lib/search.py", line 40\n    raise TimeoutError("Gateway 504")', 'IO_ERR');
        });

        this.addStep(800, undefined, () => {
            this.emitLog('n2', 'THOUGHT', 'Search failed. Attempting dynamic delegation strategy.', 'RECOVERY');
        });

        // n2 does its dynamic delegation thing
        this.processDynamicChain('n2', 'n4'); 

        // === INSERT SYSTEM INTERVENTION HERE ===
        // We simulate a pause just before the final synthesis node (n4) starts.
        this.addStep(0, 'AWAITING_APPROVAL', () => {
            // Emit the specific log that triggers the ApprovalCard in OutputPane
            // message="SAFETY_PATTERN_TRIGGERED", metadata="INTERVENTION"
            this.emitLog('CORTEX', 'INFO', 'SAFETY_PATTERN_TRIGGERED', 'INTERVENTION');
        }); 
        
        // 4. Synthesis (n4) runs (After approval)
        this.simulateAgentExecution('n4', 3000, 2500);

        // 5. Completion
        this.addStep(1000, 'COMPLETED');
    }

    private processDynamicChain(currentId: string, finalDependentId: string) {
        const isRoot = currentId === 'n2';
        // Force delegation for n2 to show feature
        const shouldDelegate = isRoot; 
        
        if (shouldDelegate) {
            const newAgentId = `${currentId}_sub_A`;
            const reason = "Search failed; spawning specialist.";

            // This delay simulates the LLM generation time
            this.addStep(1000, undefined, () => {
                const output = generateDelegationArtifact(reason, currentId, newAgentId);
                SESSION_ARTIFACTS[currentId] = { result: output };

                this.activeAgents = this.activeAgents.filter(id => id !== currentId);
                this.completedAgents.push(currentId);
                this.totalTokens += 500;
                
                this.invocations.push({
                    id: `inv-${currentId}`,
                    agent_id: currentId,
                    status: 'success',
                    tokens_used: 500,
                    latency_ms: 1200,
                    artifact_id: `mock-art-${currentId}`
                });

                // Update Topology
                this.topology.nodes.push(newAgentId);
                this.topology.edges.push({ from: currentId, to: newAgentId });
                // Rewire: n2 -> n4 becomes n2 -> sub -> n4
                this.topology.edges = this.topology.edges.filter(e => !(e.from === currentId && e.to === finalDependentId));
                this.topology.edges.push({ from: newAgentId, to: finalDependentId });

                this.signatures[currentId] = `hash_${currentId}`;
            });

            // Start New Agent
            this.addStep(500, undefined, () => {
                this.activeAgents.push(newAgentId);
                this.emitLog(newAgentId, 'THOUGHT', 'I have been spawned to handle the missing documentation.', 'INIT');
            });

            this.simulateAgentCompletion(newAgentId, 2000, 600, true);

        } else {
            SESSION_ARTIFACTS[currentId] = { 
                result: `Analysis complete for node ${currentId}. Validated 100% data points.` 
            };
            this.simulateAgentCompletion(currentId, 1500 + Math.random() * 1000, 600, true);
        }
    }

    private simulateAgentExecution(id: string, duration: number, tokens: number) {
        this.addStep(200, undefined, () => {
            if (!this.activeAgents.includes(id)) {
                this.activeAgents.push(id);
            }
        });
        this.simulateAgentCompletion(id, duration, tokens, false);
    }

    private simulateAgentCompletion(id: string, duration: number, tokens: number, isDynamic: boolean) {
        this.addStep(duration, undefined, () => {
            this.activeAgents = this.activeAgents.filter(a => a !== id);
            this.completedAgents.push(id);
            this.totalTokens += tokens;
            this.signatures[id] = `hash_${Math.floor(Math.random()*10000).toString(16)}`;

            const invocation: any = {
                id: `inv-${id}`,
                agent_id: id,
                status: 'success',
                tokens_used: tokens,
                latency_ms: duration,
                artifact_id: `mock-art-${id}`
            };

            // n3 uses execute_python to generate artifacts
            if (id === 'n3') {
                invocation.tools_used = ['execute_python'];
            }

            this.invocations.push(invocation);
        });
    }

    private addStep(delay: number, statusOverride?: string, action?: () => void) {
        // We defer the state snapshot to execution time (in runLoop)
        // by wrapping the current state logic into the stored action or checking it dynamically
        // BUT, since we are defining the plan sequentially, we need the simulation step object
        // to hold the *intent* of the change, and we apply it when the timer hits.
        
        // However, the `steps` array in the original mock assumes pre-calculated state snapshots.
        // To support `action` callback modifying state mid-flight, we need to adapt `runLoop`.
        
        this.steps.push({
            delay,
            state: {
                status: statusOverride || 'RUNNING',
                active_agents: [], // These will be filled dynamically in runLoop based on `this.activeAgents`
                completed_agents: [],
                failed_agents: [],
                total_tokens_used: 0,
                invocations: []
            },
            signatures: {},
            topology: { nodes: [], edges: [] },
            action // Store the action to be run before sending update
        });
    }

    private runLoop() {
        if (this.currentStep >= this.steps.length) {
            this.close();
            return;
        }

        const step = this.steps[this.currentStep];
        
        // 1. EXECUTE ACTION (Mutates this.activeAgents, this.topology, etc.)
        if (step.action) {
            step.action();
        }

        // 2. CONSTRUCT DYNAMIC STATE
        // We ignore the empty placeholders in `step.state` and build from class properties
        const dynamicState = {
            status: step.state.status === 'RUNNING' ? 'RUNNING' : step.state.status,
            active_agents: [...this.activeAgents],
            completed_agents: [...this.completedAgents],
            failed_agents: [],
            total_tokens_used: this.totalTokens,
            invocations: JSON.parse(JSON.stringify(this.invocations))
        };

        // 3. Send the Update
        const message = {
            type: 'state_update',
            state: dynamicState,
            signatures: { ...this.signatures },
            topology: JSON.parse(JSON.stringify(this.topology))
        };

        if (this.onmessage) {
            this.onmessage({ data: JSON.stringify(message) });
        }

        // 4. CHECK FOR INTERVENTION (PAUSE)
        if (dynamicState.status === 'AWAITING_APPROVAL') {
            console.log('[MOCK WS] Simulation paused for approval.');
            this.isPaused = true;
            this.currentStep++; 
            return; // EXIT LOOP
        }

        // 5. Schedule next step
        this.timer = setTimeout(() => {
            this.currentStep++;
            this.runLoop();
        }, step.delay);
    }
}

// === MOCK ARTIFACT STORAGE ===

const MOCK_ARTIFACTS: ArtifactMetadata[] = [
    {
        run_id: 'mock-run-1234567890',
        workflow_id: 'data_analysis_v2',
        user_directive: 'Analyze Q3 financials and generate variance report',
        created_at: new Date(Date.now() - 2 * 60 * 1000).toISOString(), // 2 minutes ago
        expires_at: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000).toISOString(), // 7 days from now
        status: 'completed',
        artifacts: [
            {
                filename: 'latency_variance_analysis.png',
                agent_id: 'visualization_agent',
                generated_at: new Date(Date.now() - 1.5 * 60 * 1000).toISOString(),
                size_bytes: 45120,
                content_type: 'image/png'
            },
            {
                filename: 'metrics_summary.json',
                agent_id: 'data_processor',
                generated_at: new Date(Date.now() - 1.8 * 60 * 1000).toISOString(),
                size_bytes: 2048,
                content_type: 'application/json'
            },
            // UPDATED: Add JSON file here for sidebar testing
            {
                filename: 'fictional_data.json',
                agent_id: 'data_generator',
                generated_at: new Date(Date.now() - 1.9 * 60 * 1000).toISOString(),
                size_bytes: 1024,
                content_type: 'application/json'
            }
        ]
    },
    {
        run_id: 'mock-run-0987654321',
        workflow_id: 'report_generation',
        user_directive: 'Generate executive summary from research findings',
        created_at: new Date(Date.now() - 60 * 60 * 1000).toISOString(), // 1 hour ago
        expires_at: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000).toISOString(),
        status: 'completed',
        artifacts: [
            {
                filename: 'executive_summary.md',
                agent_id: 'document_writer',
                generated_at: new Date(Date.now() - 58 * 60 * 1000).toISOString(),
                size_bytes: 8192,
                content_type: 'text/markdown'
            },
            {
                filename: 'research_chart.png',
                agent_id: 'visualization_agent',
                generated_at: new Date(Date.now() - 59 * 60 * 1000).toISOString(),
                size_bytes: 52000,
                content_type: 'image/png'
            }
        ]
    },
    {
        run_id: 'mock-run-5555555555',
        workflow_id: 'system_audit',
        user_directive: 'Audit system logs and generate security report',
        created_at: new Date(Date.now() - 25 * 60 * 60 * 1000).toISOString(), // 25 hours ago
        expires_at: new Date(Date.now() + 6 * 24 * 60 * 60 * 1000).toISOString(),
        status: 'completed',
        artifacts: [
            {
                filename: 'security_report.pdf',
                agent_id: 'security_analyzer',
                generated_at: new Date(Date.now() - 24.5 * 60 * 60 * 1000).toISOString(),
                size_bytes: 156000,
                content_type: 'application/pdf'
            },
            {
                filename: 'anomaly_log.csv',
                agent_id: 'log_processor',
                generated_at: new Date(Date.now() - 24.8 * 60 * 60 * 1000).toISOString(),
                size_bytes: 12400,
                content_type: 'text/csv'
            }
        ]
    }
];

export async function mockGetAllArtifacts(): Promise<ArtifactMetadata[]> {
    console.log('[MOCK] Fetching all artifacts');
    return new Promise((resolve) => {
        setTimeout(() => {
            resolve(MOCK_ARTIFACTS);
        }, 300);
    });
}

export async function mockGetRunArtifacts(runId: string): Promise<ArtifactMetadata | null> {
    console.log(`[MOCK] Fetching artifacts for run ${runId}`);
    return new Promise((resolve) => {
        setTimeout(() => {
            const metadata = MOCK_ARTIFACTS.find(a => a.run_id === runId);
            resolve(metadata || null);
        }, 300);
    });
}